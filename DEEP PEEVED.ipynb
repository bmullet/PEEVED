{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEPLY PEEVED: Neural Nets for Volcano Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from util import load_hypocenters, PuuOo, load_puuoo_eqs\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "from sklearn import ensemble as ml_models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset/dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from util import load_hypocenters, PuuOo, load_puuoo_eqs\n",
    "\n",
    "\n",
    "class BaseEarthquakes(data.Dataset):\n",
    "    \"\"\"Earthquake and Eruption Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, root, eruption_csv_path, eq_csv_path, split):\n",
    "        self.root  = root\n",
    "        self.split = split\n",
    "        self.eruption_csv_path = eruption_csv_path\n",
    "        self.eq_csv_path = eq_csv_path\n",
    "        self._load_data()\n",
    "        self._normalize()\n",
    "    \n",
    "    def _normalize(self):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.x)\n",
    "        self.x = scaler.transform(self.x)\n",
    "    \n",
    "    def _load_data(self):\n",
    "        # Create data list via train, val split\n",
    "        p = PuuOo(eruption_csv_path)\n",
    "        time, lat, lon, depth, mag = load_puuoo_eqs(eq_csv_path)\n",
    "        \n",
    "        if self.split in [\"train\", \"val\"]:\n",
    "            random.seed(0)\n",
    "            percent_train = 0.8 \n",
    "            \n",
    "            # Make additional array for erupting or not\n",
    "            erupt = np.array([p.was_erupting(t) for t in time])\n",
    "            \n",
    "            # Get indices of eruption and non-eruption earthquakes so we can split both\n",
    "            eruption_idx    = [i for i, e in enumerate(erupt) if e == True]\n",
    "            no_eruption_idx = [i for i, e in enumerate(erupt) if e == False]\n",
    "\n",
    "            num_train_eruptions = int(percent_train * len(eruption_idx))\n",
    "            num_val_eruptions   = len(eruption_idx) - num_train_eruptions\n",
    "\n",
    "            num_train_no_eruptions = int(percent_train * len(no_eruption_idx))\n",
    "            num_val_no_eruptions   = len(no_eruption_idx) - num_train_eruptions\n",
    "\n",
    "            train_idx = sorted(random.sample(eruption_idx, num_train_eruptions))\n",
    "            val_idx   = sorted(list(set(eruption_idx) - set(train_idx)))\n",
    "            train_idx += sorted(random.sample(no_eruption_idx, num_train_no_eruptions))\n",
    "            val_idx   += sorted(list(set(no_eruption_idx) - set(train_idx)))\n",
    "            \n",
    "            if self.split == \"train\":\n",
    "                idx = train_idx\n",
    "            elif self.split == \"val\":\n",
    "                idx = val_idx\n",
    "            \n",
    "            # Shuffle for data loader\n",
    "            random.shuffle(idx)\n",
    "            \n",
    "            self.time = np.array(time)[idx]\n",
    "            self.lat = np.array(lat)[idx]\n",
    "            self.lon = np.array(lon)[idx]\n",
    "            self.depth = np.array(depth)[idx]\n",
    "            self.mag = np.array(mag)[idx]\n",
    "            self.erupt = np.array(erupt)[idx]\n",
    "            \n",
    "            self.y = self.erupt\n",
    "            self.x = np.array([self.lat, self.lon, \\\n",
    "                               self.depth, self.mag]).T\n",
    "                   \n",
    "        else:\n",
    "            raise ValueError(\"Invalid split name: {}\".format(self.split))\n",
    "\n",
    "    def _get_label_weights(self):\n",
    "        # Get weights for a given dataset\n",
    "        num_erupt = np.sum(self.y)\n",
    "        total = len(self.y)\n",
    "        weights = [1, total/num_erupt]\n",
    "\n",
    "        return weights\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.erupt)\n",
    "\n",
    "\n",
    "class NoDerivedFeatures(BaseEarthquakes):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(NoDerivedFeatures, self).__init__(**kwargs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "class ExtraFeatures(BaseEarthquakes):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(NoDerivedFeatures, self).__init__(**kwargs)\n",
    "        self.derive_extra_features()\n",
    "    \n",
    "    def derive_extra_features(self):\n",
    "        pass\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "eruption_csv_path = 'PuuOo.csv'\n",
    "eq_csv_path       = 'puuoo_earthquakes.csv' \n",
    "\n",
    "dataset_train = NoDerivedFeatures(\n",
    "        root=\".\",\n",
    "        eruption_csv_path=eruption_csv_path, \n",
    "        eq_csv_path=eq_csv_path,    \n",
    "        split=\"train\",\n",
    "    )\n",
    "\n",
    "dataset_val = NoDerivedFeatures(\n",
    "        root=\".\",\n",
    "        eruption_csv_path=eruption_csv_path, \n",
    "        eq_csv_path=eq_csv_path,    \n",
    "        split=\"val\",\n",
    "    )\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size=50)\n",
    "loader_val = DataLoader(dataset_val, batch_size=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_two_layer_model(input_features, hidden_layer_sizes=[1000,500], output_size=1):\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_features, hidden_layer_sizes[0]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_sizes[0], hidden_layer_sizes[1]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_sizes[1],output_size)\n",
    "    )\n",
    "    \n",
    "    return model.double()\n",
    "\n",
    "def get_four_layer_model(input_features, hidden_layer_sizes=[1000,1000,1000,1000], output_size=1):\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_features, hidden_layer_sizes[0]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_sizes[0], hidden_layer_sizes[1]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_sizes[1], hidden_layer_sizes[2]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_sizes[2], hidden_layer_sizes[3]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_sizes[3],output_size),\n",
    "    )\n",
    "    \n",
    "    return model.double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.modules of Sequential(\n",
      "  (0): Linear(in_features=4, out_features=1000, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=1000, out_features=1, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model = get_four_layer_model(4)\n",
    "print(model.modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    num_pos     = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = torch.nn.functional.sigmoid(model(x))\n",
    "            \n",
    "            preds = torch.squeeze((scores > 0.5).long())\n",
    "\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "            num_pos += (preds).sum()\n",
    "            \n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Accuracy on ' + loader.dataset.split + ': Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        print('Num pos: %d' % num_pos)\n",
    "def train_model(model, optimizer, epochs=1):\n",
    "    \n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    \n",
    "    weights = loader_train.dataset._get_label_weights()\n",
    "    weights = torch.tensor(weights)\n",
    "    print('Weghts are: ', weights)\n",
    "    #criterion = nn.CrossEntropyLoss(weight=weights.double())\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=weights[1])\n",
    "    #criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion.to(device)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            \n",
    "            y = torch.unsqueeze(y,1)\n",
    "           \n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "                    \n",
    "            scores = model(x)\n",
    "            loss = criterion(scores, y.float())\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "        if e % print_every == 0:\n",
    "            print('Epoch %d, loss = %.4f' % (e, loss.item()))\n",
    "            check_accuracy(loader_train, model)\n",
    "            check_accuracy(loader_val, model)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weghts are:  tensor([1.0000, 5.2500])\n",
      "Epoch 0, loss = 1.2412\n",
      "Accuracy on train: Got 1929 / 5187 correct (37.19)\n",
      "Num pos: 3996\n",
      "Accuracy on val: Got 495 / 1298 correct (38.14)\n",
      "Num pos: 961\n",
      "\n",
      "Epoch 10, loss = 1.2462\n",
      "Accuracy on train: Got 2787 / 5187 correct (53.73)\n",
      "Num pos: 2888\n",
      "Accuracy on val: Got 662 / 1298 correct (51.00)\n",
      "Num pos: 720\n",
      "\n",
      "Epoch 20, loss = 1.2013\n",
      "Accuracy on train: Got 3119 / 5187 correct (60.13)\n",
      "Num pos: 2430\n",
      "Accuracy on val: Got 736 / 1298 correct (56.70)\n",
      "Num pos: 610\n",
      "\n",
      "Epoch 30, loss = 1.1722\n",
      "Accuracy on train: Got 3153 / 5187 correct (60.79)\n",
      "Num pos: 2422\n",
      "Accuracy on val: Got 752 / 1298 correct (57.94)\n",
      "Num pos: 588\n",
      "\n",
      "Epoch 40, loss = 1.1467\n",
      "Accuracy on train: Got 3212 / 5187 correct (61.92)\n",
      "Num pos: 2369\n",
      "Accuracy on val: Got 761 / 1298 correct (58.63)\n",
      "Num pos: 569\n",
      "\n",
      "Epoch 50, loss = 1.1034\n",
      "Accuracy on train: Got 3140 / 5187 correct (60.54)\n",
      "Num pos: 2481\n",
      "Accuracy on val: Got 750 / 1298 correct (57.78)\n",
      "Num pos: 598\n",
      "\n",
      "Epoch 60, loss = 1.1052\n",
      "Accuracy on train: Got 3243 / 5187 correct (62.52)\n",
      "Num pos: 2332\n",
      "Accuracy on val: Got 760 / 1298 correct (58.55)\n",
      "Num pos: 564\n",
      "\n",
      "Epoch 70, loss = 1.0666\n",
      "Accuracy on train: Got 3163 / 5187 correct (60.98)\n",
      "Num pos: 2460\n",
      "Accuracy on val: Got 756 / 1298 correct (58.24)\n",
      "Num pos: 576\n",
      "\n",
      "Epoch 80, loss = 1.0656\n",
      "Accuracy on train: Got 3148 / 5187 correct (60.69)\n",
      "Num pos: 2517\n",
      "Accuracy on val: Got 732 / 1298 correct (56.39)\n",
      "Num pos: 602\n",
      "\n",
      "Epoch 90, loss = 1.0791\n",
      "Accuracy on train: Got 3127 / 5187 correct (60.29)\n",
      "Num pos: 2546\n",
      "Accuracy on val: Got 726 / 1298 correct (55.93)\n",
      "Num pos: 604\n",
      "\n",
      "Epoch 100, loss = 1.0835\n",
      "Accuracy on train: Got 3194 / 5187 correct (61.58)\n",
      "Num pos: 2461\n",
      "Accuracy on val: Got 742 / 1298 correct (57.16)\n",
      "Num pos: 580\n",
      "\n",
      "Epoch 110, loss = 1.0350\n",
      "Accuracy on train: Got 3231 / 5187 correct (62.29)\n",
      "Num pos: 2432\n",
      "Accuracy on val: Got 752 / 1298 correct (57.94)\n",
      "Num pos: 566\n",
      "\n",
      "Epoch 120, loss = 1.0684\n",
      "Accuracy on train: Got 3250 / 5187 correct (62.66)\n",
      "Num pos: 2395\n",
      "Accuracy on val: Got 770 / 1298 correct (59.32)\n",
      "Num pos: 556\n",
      "\n",
      "Epoch 130, loss = 1.0349\n",
      "Accuracy on train: Got 3260 / 5187 correct (62.85)\n",
      "Num pos: 2425\n",
      "Accuracy on val: Got 746 / 1298 correct (57.47)\n",
      "Num pos: 578\n",
      "\n",
      "Epoch 140, loss = 1.1296\n",
      "Accuracy on train: Got 3291 / 5187 correct (63.45)\n",
      "Num pos: 2346\n",
      "Accuracy on val: Got 756 / 1298 correct (58.24)\n",
      "Num pos: 542\n",
      "\n",
      "Epoch 150, loss = 1.0354\n",
      "Accuracy on train: Got 3363 / 5187 correct (64.84)\n",
      "Num pos: 2274\n",
      "Accuracy on val: Got 775 / 1298 correct (59.71)\n",
      "Num pos: 539\n",
      "\n",
      "Epoch 160, loss = 1.0369\n",
      "Accuracy on train: Got 3391 / 5187 correct (65.37)\n",
      "Num pos: 2240\n",
      "Accuracy on val: Got 772 / 1298 correct (59.48)\n",
      "Num pos: 530\n",
      "\n",
      "Epoch 170, loss = 0.9866\n",
      "Accuracy on train: Got 3364 / 5187 correct (64.85)\n",
      "Num pos: 2279\n",
      "Accuracy on val: Got 763 / 1298 correct (58.78)\n",
      "Num pos: 535\n",
      "\n",
      "Epoch 180, loss = 1.0722\n",
      "Accuracy on train: Got 3340 / 5187 correct (64.39)\n",
      "Num pos: 2317\n",
      "Accuracy on val: Got 755 / 1298 correct (58.17)\n",
      "Num pos: 555\n",
      "\n",
      "Epoch 190, loss = 1.1152\n",
      "Accuracy on train: Got 3293 / 5187 correct (63.49)\n",
      "Num pos: 2434\n",
      "Accuracy on val: Got 742 / 1298 correct (57.16)\n",
      "Num pos: 584\n",
      "\n",
      "Epoch 200, loss = 0.9593\n",
      "Accuracy on train: Got 3402 / 5187 correct (65.59)\n",
      "Num pos: 2253\n",
      "Accuracy on val: Got 766 / 1298 correct (59.01)\n",
      "Num pos: 544\n",
      "\n",
      "Epoch 210, loss = 0.9777\n",
      "Accuracy on train: Got 3391 / 5187 correct (65.37)\n",
      "Num pos: 2324\n",
      "Accuracy on val: Got 756 / 1298 correct (58.24)\n",
      "Num pos: 558\n",
      "\n",
      "Epoch 220, loss = 1.0652\n",
      "Accuracy on train: Got 3324 / 5187 correct (64.08)\n",
      "Num pos: 2419\n",
      "Accuracy on val: Got 749 / 1298 correct (57.70)\n",
      "Num pos: 569\n",
      "\n",
      "Epoch 230, loss = 0.9692\n",
      "Accuracy on train: Got 3387 / 5187 correct (65.30)\n",
      "Num pos: 2318\n",
      "Accuracy on val: Got 753 / 1298 correct (58.01)\n",
      "Num pos: 549\n",
      "\n",
      "Epoch 240, loss = 1.0387\n",
      "Accuracy on train: Got 3375 / 5187 correct (65.07)\n",
      "Num pos: 2354\n",
      "Accuracy on val: Got 752 / 1298 correct (57.94)\n",
      "Num pos: 568\n",
      "\n",
      "Epoch 250, loss = 0.9477\n",
      "Accuracy on train: Got 3471 / 5187 correct (66.92)\n",
      "Num pos: 2198\n",
      "Accuracy on val: Got 778 / 1298 correct (59.94)\n",
      "Num pos: 520\n",
      "\n",
      "Epoch 260, loss = 0.9658\n",
      "Accuracy on train: Got 3491 / 5187 correct (67.30)\n",
      "Num pos: 2210\n",
      "Accuracy on val: Got 779 / 1298 correct (60.02)\n",
      "Num pos: 521\n",
      "\n",
      "Epoch 270, loss = 0.9451\n",
      "Accuracy on train: Got 3521 / 5187 correct (67.88)\n",
      "Num pos: 2148\n",
      "Accuracy on val: Got 785 / 1298 correct (60.48)\n",
      "Num pos: 505\n",
      "\n",
      "Epoch 280, loss = 0.9769\n",
      "Accuracy on train: Got 3468 / 5187 correct (66.86)\n",
      "Num pos: 2213\n",
      "Accuracy on val: Got 782 / 1298 correct (60.25)\n",
      "Num pos: 514\n",
      "\n",
      "Epoch 290, loss = 0.9377\n",
      "Accuracy on train: Got 3480 / 5187 correct (67.09)\n",
      "Num pos: 2257\n",
      "Accuracy on val: Got 773 / 1298 correct (59.55)\n",
      "Num pos: 543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "print_every = 10\n",
    "\n",
    "device = torch.device('cpu')\n",
    "dtype = torch.float64\n",
    "\n",
    "#model = get_two_layer_model(4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, optimizer, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8095238095238095\n",
      "0.8089368258859785\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(1-loader_train.dataset.y)/len(loader_train.dataset.y))\n",
    "print(np.sum(1-loader_val.dataset.y)/len(loader_val.dataset.y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weghts are:  tensor([1.0000, 5.2500])\n",
      "Epoch 0, loss = 1.4757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/anaconda3/envs/cs229/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train: Got 997 / 5187 correct (19.22)\n",
      "Num pos: 5178\n",
      "Accuracy on val: Got 250 / 1298 correct (19.26)\n",
      "Num pos: 1296\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-538aa9ae9e8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-86-58717f187b60>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs229/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs229/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs229/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs229/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs229/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "print_every = 10\n",
    "\n",
    "device = torch.device('cpu')\n",
    "dtype = torch.float64\n",
    "\n",
    "#model = get_four_layer_model(4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, optimizer, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
