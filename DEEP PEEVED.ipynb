{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEPLY PEEVED: Neural Nets for Volcano Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from util import load_hypocenters, PuuOo, load_puuoo_eqs\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "from sklearn import ensemble as ml_models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset/dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from util import load_hypocenters, PuuOo, load_puuoo_eqs\n",
    "\n",
    "\n",
    "class BaseEarthquakes(data.Dataset):\n",
    "    \"\"\"Earthquake and Eruption Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, root, eruption_csv_path, eq_csv_path, split):\n",
    "        self.root  = root\n",
    "        self.split = split\n",
    "        self.eruption_csv_path = eruption_csv_path\n",
    "        self.eq_csv_path = eq_csv_path\n",
    "        self._load_data()\n",
    "    \n",
    "    \n",
    "    def _load_data(self):\n",
    "        # Create data list via train, val split\n",
    "        p = PuuOo(eruption_csv_path)\n",
    "        time, lat, lon, depth, mag = load_puuoo_eqs(eq_csv_path)\n",
    "        \n",
    "        if self.split in [\"train\", \"val\"]:\n",
    "            random.seed(0)\n",
    "            percent_train = 0.8 \n",
    "            \n",
    "            # Make additional array for erupting or not\n",
    "            erupt = np.array([p.was_erupting(t) for t in time])\n",
    "            \n",
    "            # Get indices of eruption and non-eruption earthquakes so we can split both\n",
    "            eruption_idx    = [i for i, e in enumerate(erupt) if e == True]\n",
    "            no_eruption_idx = [i for i, e in enumerate(erupt) if e == False]\n",
    "\n",
    "            num_train_eruptions = int(percent_train * len(eruption_idx))\n",
    "            num_val_eruptions   = len(eruption_idx) - num_train_eruptions\n",
    "\n",
    "            num_train_no_eruptions = int(percent_train * len(no_eruption_idx))\n",
    "            num_val_no_eruptions   = len(no_eruption_idx) - num_train_eruptions\n",
    "\n",
    "            train_idx = sorted(random.sample(eruption_idx, num_train_eruptions))\n",
    "            val_idx   = sorted(list(set(eruption_idx) - set(train_idx)))\n",
    "            train_idx += sorted(random.sample(no_eruption_idx, num_train_no_eruptions))\n",
    "            val_idx   += sorted(list(set(no_eruption_idx) - set(train_idx)))\n",
    "            \n",
    "            if self.split == \"train\":\n",
    "                idx = train_idx\n",
    "            elif self.split == \"val\":\n",
    "                idx = val_idx\n",
    "            \n",
    "            # Shuffle for data loader\n",
    "            random.shuffle(idx)\n",
    "            \n",
    "            self.time = np.array(time)[idx]\n",
    "            self.lat = np.array(lat)[idx]\n",
    "            self.lon = np.array(lon)[idx]\n",
    "            self.depth = np.array(depth)[idx]\n",
    "            self.mag = np.array(mag)[idx]\n",
    "            self.erupt = np.array(erupt)[idx]\n",
    "                   \n",
    "        else:\n",
    "            raise ValueError(\"Invalid split name: {}\".format(self.split))\n",
    "\n",
    "    def _get_label_weights(self):\n",
    "        # Get weights for a given dataset\n",
    "        ids = [self._get_disaster_id(sample_name) for sample_name in self.files]\n",
    "        id_counts = Counter(ids)\n",
    "\n",
    "        total = len(ids)\n",
    "\n",
    "        weights = [min(total/id_counts[i], 15) for i in range(self.num_classes)]\n",
    "\n",
    "        return weights\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.erupt)\n",
    "\n",
    "\n",
    "class NoDerivedFeatures(BaseEarthquakes):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(NoDerivedFeatures, self).__init__(**kwargs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        y = self.erupt[index]\n",
    "        x = np.array([self.lat[index], self.lon[index], self.depth[index], self.mag[index]])\n",
    "        return x,y\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[  19.3167, -155.2212,    4.6000,    1.9400],\n",
      "        [  19.3223, -155.2173,    4.2800,    1.5900],\n",
      "        [  19.3415, -155.1992,    7.1600,    1.7400],\n",
      "        [  19.3895, -155.4385,   11.3300,    2.0200],\n",
      "        [  19.4042, -155.4448,    9.9800,    1.9600]], dtype=torch.float64)\n",
      "tensor([False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "eruption_csv_path = 'PuuOo.csv'\n",
    "eq_csv_path       = 'puuoo_earthquakes.csv' \n",
    "\n",
    "dataset_train = NoDerivedFeatures(\n",
    "        root=\".\",\n",
    "        eruption_csv_path=eruption_csv_path, \n",
    "        eq_csv_path=eq_csv_path,    \n",
    "        split=\"train\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "dataset_val = NoDerivedFeatures(\n",
    "        root=\".\",\n",
    "        eruption_csv_path=eruption_csv_path, \n",
    "        eq_csv_path=eq_csv_path,    \n",
    "        split=\"train\",\n",
    "    )\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size=5)\n",
    "loader_val = DataLoader(dataset_val, batch_size=5)\n",
    "\n",
    "for i, (x,y) in enumerate(loader_train):\n",
    "    print(i)\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_two_layer_model(input_features, hidden_layer_sizes=[1000,500], output_size=2):\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_features, hidden_layer_sizes[0]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_sizes[0], hidden_layer_sizes[1]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer_sizes[1],output_size),\n",
    "    )\n",
    "    \n",
    "    return model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.modules of Sequential(\n",
      "  (0): Linear(in_features=4, out_features=1000, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=500, out_features=2, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model = get_two_layer_model(4)\n",
    "print(model.modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.split == \"train\":\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "def train_model(model, optimizer, epochs=1):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 10, loss = 0.2359\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 20, loss = 0.3775\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 30, loss = 0.0242\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 40, loss = 0.6370\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 50, loss = 0.5159\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 60, loss = 0.5195\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 70, loss = 0.3158\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 80, loss = 0.7135\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 90, loss = 0.5174\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 100, loss = 0.0532\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 110, loss = 0.5657\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 120, loss = 0.0988\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 130, loss = 0.6743\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 140, loss = 0.4686\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 150, loss = 0.4602\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 160, loss = 0.6848\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 170, loss = 0.4184\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 180, loss = 0.6928\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 190, loss = 0.1969\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 200, loss = 0.2598\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 210, loss = 0.0341\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 220, loss = 0.2997\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 230, loss = 0.2820\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 240, loss = 0.4522\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 250, loss = 0.6025\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 260, loss = 0.1104\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 270, loss = 0.1114\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 280, loss = 0.2692\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 290, loss = 0.5019\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 300, loss = 0.0799\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 310, loss = 0.8107\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 320, loss = 0.7999\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 330, loss = 0.0810\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 340, loss = 1.1574\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 350, loss = 0.7352\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 360, loss = 0.2075\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 370, loss = 0.2767\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 380, loss = 0.8292\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 390, loss = 0.2070\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 400, loss = 0.1070\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 410, loss = 0.8858\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 420, loss = 0.9772\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 430, loss = 0.1734\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 440, loss = 0.4684\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 450, loss = 0.6323\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 460, loss = 0.1665\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 470, loss = 1.3172\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 480, loss = 0.1053\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 490, loss = 0.0432\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 500, loss = 0.5812\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 510, loss = 0.1576\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 520, loss = 0.2043\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 530, loss = 0.6228\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 540, loss = 0.5513\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 550, loss = 0.0995\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 560, loss = 0.1193\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 570, loss = 0.0980\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 580, loss = 0.1154\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 590, loss = 0.5528\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n",
      "Iteration 600, loss = 1.1239\n",
      "Checking accuracy on validation set\n",
      "Got 4512 / 5116 correct (88.19)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-ec6fad265ccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-dc32e1bddbe9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, epochs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# This is the backwards pass: compute the gradient of the loss with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# respect to each  parameter of the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Actually update the parameters of the model using the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs229/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs229/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.02\n",
    "print_every = 10\n",
    "device = torch.device('cpu')\n",
    "dtype = torch.float64\n",
    "\n",
    "model = get_two_layer_model(4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
