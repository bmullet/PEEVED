{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for time series prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/\n",
    "\n",
    "# multivariate cnn example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from util import load_hypocenters, PuuOo, load_puuoo_eqs\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEarthquakes():\n",
    "    \"\"\"Earthquake and Eruption Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, root, eruption_csv_path, eq_csv_path, split):\n",
    "        self.root  = root\n",
    "        self.split = split\n",
    "        self.eruption_csv_path = eruption_csv_path\n",
    "        self.eq_csv_path = eq_csv_path\n",
    "        self._get_east_rift_zone()\n",
    "        self._load_data()\n",
    "\n",
    "        self._normalize()\n",
    "        \n",
    "    def _get_east_rift_zone(self): \n",
    "        self.p = PuuOo(self.eruption_csv_path)\n",
    "        time, lat, lon, depth, mag = load_puuoo_eqs(self.eq_csv_path)\n",
    "        \n",
    "        latpts = np.array([19.3,19.5])\n",
    "        lonpts = np.array([-155.5,-155])\n",
    "        A      = np.array([lonpts,[1,1]]).T\n",
    "        line   = np.linalg.solve(A, latpts)   \n",
    "        croplocs = lat - line[0]*lon - line[1]        \n",
    "        idx = [j for j in range(len(lon)) if croplocs[j]<=0]\n",
    "        \n",
    "        self.time = np.array(time)[idx]\n",
    "        self.lat = np.array(lat)[idx]\n",
    "        self.lon = np.array(lon)[idx]\n",
    "        self.depth = np.array(depth)[idx]\n",
    "        self.mag = np.array(mag)[idx]\n",
    "    \n",
    "    def _normalize(self):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.x)\n",
    "        self.x = scaler.transform(self.x)\n",
    "    \n",
    "    def _load_data(self):\n",
    "        # Create data list via train, val split\n",
    "\n",
    "        if self.split in [\"train\", \"val\", \"test\"]:\n",
    "            random.seed(0)\n",
    "            percent_train = 0.7 \n",
    "            percent_dev   = 0.2 # Percent test is what is left\n",
    "            \n",
    "            # Make additional array for erupting or not\n",
    "            erupt = np.array([self.p.was_erupting(t) for t in self.time])\n",
    "            \n",
    "            # Get indices of eruption and non-eruption earthquakes so we can split both\n",
    "            eruption_idx    = [i for i, e in enumerate(erupt) if e == True]\n",
    "            no_eruption_idx = [i for i, e in enumerate(erupt) if e == False]\n",
    "\n",
    "            num_train_eruptions = int(percent_train * len(eruption_idx))\n",
    "            num_val_eruptions   = int(percent_dev * len(eruption_idx))\n",
    "            num_test_eruptions  = len(eruption_idx) - num_val_eruptions - num_train_eruptions\n",
    "\n",
    "            num_train_no_eruptions = int(percent_train * len(no_eruption_idx))\n",
    "            num_val_no_eruptions   = int(percent_dev * len(no_eruption_idx))\n",
    "            num_test_no_eruptions  = len(no_eruption_idx) - num_val_no_eruptions - num_train_no_eruptions\n",
    "            \n",
    "            train_idx = sorted(random.sample(eruption_idx, num_train_eruptions))\n",
    "            remaining = sorted(list(set(eruption_idx) - set(train_idx)))\n",
    "            val_idx   = sorted(random.sample(remaining, num_val_eruptions))\n",
    "            test_idx  = sorted(list(set(remaining) - set(val_idx)))\n",
    "            \n",
    "            train_idx += sorted(random.sample(no_eruption_idx, num_train_no_eruptions))\n",
    "            remaining  = sorted(list(set(no_eruption_idx) - set(train_idx)))\n",
    "            val_idx   += sorted(random.sample(remaining, num_val_no_eruptions))\n",
    "            test_idx  += sorted(list(set(remaining) - set(val_idx)))\n",
    "            \n",
    "            assert(len(train_idx) + len(val_idx) + len(test_idx) == len(erupt))\n",
    "            \n",
    "            if self.split == \"train\":\n",
    "                idx = train_idx\n",
    "            elif self.split == \"val\":\n",
    "                idx = val_idx\n",
    "            elif self.split == \"test\":\n",
    "                idx = test_idx\n",
    "            \n",
    "            # Shuffle for data loader\n",
    "            \n",
    "            random.shuffle(idx)\n",
    "            self.idx = idx\n",
    "            \n",
    "            self.time = self.time[idx]\n",
    "            self.lat = self.lat[idx]\n",
    "            self.lon = self.lon[idx]\n",
    "            self.depth = self.depth[idx]\n",
    "            self.mag = self.mag[idx]\n",
    "            self.erupt = erupt[idx]\n",
    "            \n",
    "            self.y = self.erupt\n",
    "            self.x = np.array([self.lat, self.lon, \\\n",
    "                               self.depth, self.mag]).T\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid split name: {}\".format(self.split))\n",
    "\n",
    "    def _get_label_weights(self):\n",
    "        # Get weights for a given dataset\n",
    "        num_erupt = np.sum(self.y)\n",
    "        total = len(self.y)\n",
    "        weights = [1, total/num_erupt]\n",
    "\n",
    "        return weights\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.erupt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eruption_csv_path = 'PuuOo.csv'\n",
    "eq_csv_path       = 'puuoo_earthquakes.csv' \n",
    "\n",
    "dataset_train = BaseEarthquakes(\n",
    "        root=\".\",\n",
    "        eruption_csv_path=eruption_csv_path, \n",
    "        eq_csv_path=eq_csv_path,    \n",
    "        split=\"train\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.42968854,  1.44683956,  0.57251574, -1.00951239],\n",
       "       [ 0.20901947, -0.34014885,  0.21934803, -1.00951239],\n",
       "       [-0.36819613, -0.70997428, -0.28364841,  0.24119861],\n",
       "       ...,\n",
       "       [-1.06211653, -0.30406833,  1.1968021 ,  0.28508321],\n",
       "       [-0.9138699 , -0.49449334, -0.35856277, -0.13182046],\n",
       "       [-0.55113879, -0.5205515 ,  0.23718478,  1.42608272]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
